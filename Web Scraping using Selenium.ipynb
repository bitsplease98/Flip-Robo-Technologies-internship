{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findjobs(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Writing position as Data Analyst\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[1]/div/div/div/div[1]/div[2]/input').send_keys('Data Analyst')\n",
    "    #Writing Location as Banglore\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[2]/div/div/div/div[1]/div[2]/input').send_keys('Banglore')\n",
    "    #Clicking on search button\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    jt=[]\n",
    "    jl=[]\n",
    "    jc=[]\n",
    "    je=[]\n",
    "    \n",
    "    #Scraping Job titile\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "        if i.text=='':\n",
    "            jt.append('No Data')\n",
    "        else:\n",
    "            jt.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping job Location\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span'):\n",
    "        if str(i.text)=='':\n",
    "            jl.append('No Data')\n",
    "        else:\n",
    "            jl.append(str(i.text))\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Company Name\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        if i.text=='':\n",
    "            jc.append('No Data')\n",
    "        else:\n",
    "            jc.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Experience\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span'):\n",
    "        if i.text is None:\n",
    "            je.append('No Data')\n",
    "        else:\n",
    "            je.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['Job Title']=jt\n",
    "    df['Job Location']=jl\n",
    "    df['Company Name']=jc\n",
    "    df['Experience Required']=je\n",
    "    return df\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (2positions)//immediate Joiners//...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data analysts</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Category Demand Management (Rev...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Job Opportunity For Talent Data Analyst - Corn...</td>\n",
       "      <td>Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...</td>\n",
       "      <td>Cornerstone OnDemand Services India Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Consultant-Data Analyst -Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Innovsource Services Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Work from Home</td>\n",
       "      <td>Pune, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>POWER STORES E COMMERCE PRIVATE LIMITED</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                      Data analysts   \n",
       "2  Data Analyst (2positions)//immediate Joiners//...   \n",
       "3                                      Data analysts   \n",
       "4                                       Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6  Data Analyst - Category Demand Management (Rev...   \n",
       "7  Job Opportunity For Talent Data Analyst - Corn...   \n",
       "8                 Consultant-Data Analyst -Bangalore   \n",
       "9                      Data Analyst - Work from Home   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bengaluru/Bangalore   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9      Pune, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                                  Company Name Experience Required  \n",
       "0           Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                       IBM India Pvt. Limited             5-6 Yrs  \n",
       "2                           Tech Mahindra Ltd.             4-8 Yrs  \n",
       "3                       IBM India Pvt. Limited             3-5 Yrs  \n",
       "4                     Myntra Designs Pvt. Ltd.             3-5 Yrs  \n",
       "5                     Myntra Designs Pvt. Ltd.             3-8 Yrs  \n",
       "6                     Myntra Designs Pvt. Ltd.             1-4 Yrs  \n",
       "7  Cornerstone OnDemand Services India Pvt Ltd             3-5 Yrs  \n",
       "8         Innovsource Services Private Limited             2-7 Yrs  \n",
       "9      POWER STORES E COMMERCE PRIVATE LIMITED             2-5 Yrs  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=findjobs('https://www.naukri.com/')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Writing position as Data Scientist\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[1]/div/div/div/div[1]/div[2]/input').send_keys('Data Scientist')\n",
    "    #Writing Location as Banglore\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[2]/div/div/div/div[1]/div[2]/input').send_keys('Banglore')\n",
    "    time.sleep(2)\n",
    "    #Clicking on search button\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    jt=[]\n",
    "    jl=[]\n",
    "    cn=[]\n",
    "    jd=[]\n",
    "    url=[]\n",
    "    \n",
    "    #Scraping Job titile\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "        if i.text=='':\n",
    "            jt.append('No Data')\n",
    "        else:\n",
    "            jt.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping job Location\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span'):\n",
    "        if i.text=='':\n",
    "            jl.append('No Data')\n",
    "        else:\n",
    "            jl.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Company Name\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        if i.text=='':\n",
    "            cn.append('No Data')\n",
    "        else:\n",
    "            cn.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Detailed Job Description\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "        url.append(i.get_attribute('href'))\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "    for u in url:\n",
    "        driver.get(u)\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            jobdesc=driver.find_element_by_xpath('/html/body/div[1]/main/div[2]/div[2]/section[2]/div[1]')\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                jobdesc=driver.find_element_by_xpath('/html/body/div[2]/div[1]/div/div[2]/div/div/div/div/div/div/section[1]/div')\n",
    "            except Exception as e:\n",
    "                jobdesc=driver.find_element_by_xpath('/html/body/div[2]/div[1]/div/div[2]/div/div/div/div/div/section[1]/div/div[2]')\n",
    "\n",
    "        if jobdesc.text is None:\n",
    "            jd.append('No Data')\n",
    "        else:\n",
    "            jd.append(jobdesc.text.replace('\\n',' '))\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['Job Title']=jt\n",
    "    df['Job Location']=jl\n",
    "    df['Company Name']=cn\n",
    "    df['Job Description']=jd\n",
    "    return df\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job Role : Data Scientist/Data Analyst /Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Key Responsibilities Be responsible for scalin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist, Machine Learning</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>The recruitment process starts with an Online ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>RedBus</td>\n",
       "      <td>Job Role: Senior Data Scientist   Reporting To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>We are a group of tenured professors from Tier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VP - Sr. Data Scientist For Morgan Stanley, Ba...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Morgan Stanley Advantage Services</td>\n",
       "      <td>About Us Morgan Stanley is a leading global fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Global Talent Pool</td>\n",
       "      <td>Essential Duties Responsibilities Perform basi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Job Responsibilities Ability to understand a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>intelligent industrial internet systems pvt ltd.</td>\n",
       "      <td>Roles and Responsibilities - Create an industr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Looking For Data Scientist For Infogain</td>\n",
       "      <td>Noida(Sector-60 Noida), Bangalore/Bengaluru(El...</td>\n",
       "      <td>Infogain India (P) Ltd.</td>\n",
       "      <td>Dear Candidates We are looking for an Experien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                       Senior / Lead Data Scientist   \n",
       "2                   Data Scientist, Machine Learning   \n",
       "3                              Senior Data Scientist   \n",
       "4  Data analytics / Data scientist intern (work f...   \n",
       "5  VP - Sr. Data Scientist For Morgan Stanley, Ba...   \n",
       "6                                     data scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                  Sr Data Scientist   \n",
       "9            Looking For Data Scientist For Infogain   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "2  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "8            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "9  Noida(Sector-60 Noida), Bangalore/Bengaluru(El...   \n",
       "\n",
       "                                       Company Name  \\\n",
       "0                Inflexion Analytix Private Limited   \n",
       "1                       TVS CREDIT SERVICES LIMITED   \n",
       "2                                 Fractal Analytics   \n",
       "3                                            RedBus   \n",
       "4                                    TalkValley LLC   \n",
       "5                 Morgan Stanley Advantage Services   \n",
       "6                                Global Talent Pool   \n",
       "7                                 Fractal Analytics   \n",
       "8  intelligent industrial internet systems pvt ltd.   \n",
       "9                           Infogain India (P) Ltd.   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Job Role : Data Scientist/Data Analyst /Busine...  \n",
       "1  Key Responsibilities Be responsible for scalin...  \n",
       "2  The recruitment process starts with an Online ...  \n",
       "3  Job Role: Senior Data Scientist   Reporting To...  \n",
       "4  We are a group of tenured professors from Tier...  \n",
       "5  About Us Morgan Stanley is a leading global fi...  \n",
       "6  Essential Duties Responsibilities Perform basi...  \n",
       "7  Job Responsibilities Ability to understand a p...  \n",
       "8  Roles and Responsibilities - Create an industr...  \n",
       "9  Dear Candidates We are looking for an Experien...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=jobs('https://www.naukri.com/')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage. You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Writing position as Data Scientist\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[1]/div/div/div/div[1]/div[2]/input').send_keys('Data Scientist')\n",
    "    #Clicking on search button\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button').click()\n",
    "    time.sleep(2\n",
    "              )\n",
    "    #Clicking on delhi/ncr filter\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title='Delhi / NCR']\").click()\n",
    "    time.sleep(2)\n",
    "    #Clicking on 3-6lakhs filter\n",
    "    driver.find_element_by_xpath(\"//span[@class='ellipsis fleft' and @title='3-6 Lakhs']\").click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    jt=[]\n",
    "    jl=[]\n",
    "    cn=[]\n",
    "    je=[]\n",
    "    \n",
    "    #Scraping Job titile\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]'):\n",
    "        if i.text=='':\n",
    "            jt.append('No Data')\n",
    "        else:\n",
    "            jt.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping job Location\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span'):\n",
    "        if i.text=='':\n",
    "            jl.append('No Data')\n",
    "        else:\n",
    "            jl.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Company Name\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        if i.text=='':\n",
    "            cn.append('No Data')\n",
    "        else:\n",
    "            cn.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Experience\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span'):\n",
    "        if i.text is None:\n",
    "            je.append('No Data')\n",
    "        else:\n",
    "            je.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['Job Title']=jt\n",
    "    df['Job Location']=jl\n",
    "    df['Company Name']=cn\n",
    "    df['Job Description']=je\n",
    "    return df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are hiring- Data Scientist +Python- Noida</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Milliman India Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst/Scientist Big Data, Statistical T...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>The Search House (A Div of JSD Search House Pv...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Immediate Opening : Data Scientist - Python/Ma...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>GyanScore Services Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data analytics / Data scientist intern (work f...   \n",
       "2              Chaayos is Looking For Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                              Junior Data Scientist   \n",
       "5       We are hiring- Data Scientist +Python- Noida   \n",
       "6                                     Data Scientist   \n",
       "7  Data Analyst/Scientist Big Data, Statistical T...   \n",
       "8                   Business Analyst- Data Scientist   \n",
       "9  Immediate Opening : Data Scientist - Python/Ma...   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "2                                          New Delhi   \n",
       "3      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "4                             Noida(Sector-59 Noida)   \n",
       "5               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8                            Noida, Gurgaon/Gurugram   \n",
       "9                                              Noida   \n",
       "\n",
       "                                        Company Name Job Description  \n",
       "0                 Inflexion Analytix Private Limited         0-3 Yrs  \n",
       "1                                     TalkValley LLC         0-5 Yrs  \n",
       "2              Chaayos (Sunshine Teahouse Pvt. Ltd.)         0-5 Yrs  \n",
       "3                                  Fractal Analytics         3-7 Yrs  \n",
       "4                       R Systems International Ltd.         3-5 Yrs  \n",
       "5                             RANDSTAD INDIA PVT LTD         4-7 Yrs  \n",
       "6                             Milliman India Pvt Ltd         2-5 Yrs  \n",
       "7  The Search House (A Div of JSD Search House Pv...         2-7 Yrs  \n",
       "8                                              Wipro         2-5 Yrs  \n",
       "9                 GyanScore Services Private Limited         3-5 Yrs  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=jobs('https://www.naukri.com/')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company from Glassdoor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glass(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(35)\n",
    "    \n",
    "    #Writing position as Data Scientist\n",
    "    driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[3]/form/div/div[1]/div/div/input').send_keys('Data Scientist')\n",
    "    \n",
    "    #Writing Location as Noida\n",
    "    searchbox=driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[3]/form/div/div[3]/div/input')\n",
    "    searchbox.send_keys(Keys.BACKSPACE*10) #Removing previously wriiten text\n",
    "    time.sleep(2)\n",
    "    searchbox.send_keys('Noida')\n",
    "    \n",
    "    #Clicking on search button\n",
    "    driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[3]/form/div/button/span').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    cn=[]\n",
    "    days=[]\n",
    "    rating=[]\n",
    "            \n",
    "    #Scraping Company Name\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//a[@class=\" css-l2wjgv e1n63ojh0 jobLink\"]/span'):\n",
    "        cn.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping No. of days ago when job was posted\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]'):\n",
    "        days.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Ratings of the company\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//span[@class=\"css-19pjha7 e1cjmv6j1\"]'):\n",
    "        if i.text=='':\n",
    "            rating.append('No Data')\n",
    "        else:\n",
    "            rating.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['Company Name']=cn\n",
    "    df['No. of days ago when job was posted']=days\n",
    "    df['Ratings of the Company']=rating\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "      <th>Ratings of the Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ginger Webs Pvt. Ltd.</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>8d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mogli Labs India Private Limited</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dunnhumby</td>\n",
       "      <td>24h</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amploy</td>\n",
       "      <td>6d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRMNEXT</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WishFin</td>\n",
       "      <td>30d+</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Company Name No. of days ago when job was posted  \\\n",
       "0             Ginger Webs Pvt. Ltd.                                 24h   \n",
       "1                             Crowe                                  8d   \n",
       "2                    Biz2Credit Inc                                30d+   \n",
       "3  Mogli Labs India Private Limited                                  6d   \n",
       "4                         dunnhumby                                 24h   \n",
       "5                                                                  30d+   \n",
       "6                          Ericsson                                  6d   \n",
       "7                            Amploy                                  6d   \n",
       "8                           CRMNEXT                                30d+   \n",
       "9                           WishFin                                30d+   \n",
       "\n",
       "  Ratings of the Company  \n",
       "0                    3.7  \n",
       "1                    3.7  \n",
       "2                    4.0  \n",
       "3                    4.1  \n",
       "4                    5.0  \n",
       "5                    4.1  \n",
       "6                    3.7  \n",
       "7                    3.8  \n",
       "8                    3.7  \n",
       "9                    2.4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=glass('https://www.glassdoor.co.in/index.htm')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company from the page https://www.glassdoor.co.in/Salaries/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glass(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Writing position as Data Scientist\n",
    "    driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[5]').send_keys('Data Scientist')\n",
    "    \n",
    "    #Writing Location as Noida\n",
    "    locsearch=driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[6]')\n",
    "    locsearch.send_keys(Keys.BACKSPACE*10)\n",
    "    locsearch.send_keys('Noida')\n",
    "    \n",
    "    #Clicking on search button\n",
    "    driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/button').click()\n",
    "    time.sleep(8)\n",
    "    \n",
    "    mi=[]\n",
    "    ma=[]\n",
    "    av=[]\n",
    "    cn=[]\n",
    "    ra=[]\n",
    "            \n",
    "    #Scraping Company Name\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//h3[@class=\"m-0 css-g261rn\"]/a'):\n",
    "        cn.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Average salary offered by the company\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"col-12 col-lg-4 px-lg-0 d-flex align-items-baseline\"]/h3'):\n",
    "        av.append(i.text.replace('\\n',''))\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Minimum salary offered by the company\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]/p[1]'):\n",
    "        mi.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping Maximum salary offered by the company\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]/p[2]'):\n",
    "        ma.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    #Scraping ratings of the company\n",
    "    c=0\n",
    "    for i in driver.find_elements_by_xpath('//span[@class=\"m-0 css-kyx745\"]'):\n",
    "        ra.append(i.text)\n",
    "        c+=1\n",
    "        if c==10:\n",
    "            break\n",
    "            \n",
    "    df=pd.DataFrame()\n",
    "    df['Company Name']=cn\n",
    "    df['Average Salary']=av\n",
    "    df['Maximum Salary']=ma\n",
    "    df['Minimum Salary']=mi\n",
    "    df['Ratings']=ra\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,14,306</td>\n",
       "      <td>₹1,250K</td>\n",
       "      <td>₹343K</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 9,00,000</td>\n",
       "      <td>₹2,730K</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,46,533</td>\n",
       "      <td>₹2,213K</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,38,057</td>\n",
       "      <td>₹1,613K</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,39,781</td>\n",
       "      <td>₹11,622K</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,36,142</td>\n",
       "      <td>₹1,520K</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹ 13,26,575</td>\n",
       "      <td>₹2,149K</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 8,15,192</td>\n",
       "      <td>₹1,465K</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 11,35,221</td>\n",
       "      <td>₹1,809K</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,44,243</td>\n",
       "      <td>₹1,520K</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Name Average Salary Maximum Salary Minimum Salary  \\\n",
       "0  Tata Consultancy Services     ₹ 6,14,306        ₹1,250K          ₹343K   \n",
       "1                        IBM     ₹ 9,00,000        ₹2,730K          ₹586K   \n",
       "2                  Accenture    ₹ 11,46,533        ₹2,213K          ₹577K   \n",
       "3         Ericsson-Worldwide     ₹ 7,38,057        ₹1,613K          ₹355K   \n",
       "4                  Delhivery    ₹ 12,39,781       ₹11,622K          ₹450K   \n",
       "5         UnitedHealth Group    ₹ 13,36,142        ₹1,520K        ₹1,069K   \n",
       "6     Optum Global Solutions    ₹ 13,26,575        ₹2,149K          ₹350K   \n",
       "7         Valiance Solutions     ₹ 8,15,192        ₹1,465K          ₹502K   \n",
       "8              ZS Associates    ₹ 11,35,221        ₹1,809K          ₹202K   \n",
       "9                EXL Service    ₹ 11,44,243        ₹1,520K          ₹575K   \n",
       "\n",
       "  Ratings  \n",
       "0     3.9  \n",
       "1     3.9  \n",
       "2       4  \n",
       "3       4  \n",
       "4     3.8  \n",
       "5     3.6  \n",
       "6     3.9  \n",
       "7     4.1  \n",
       "8       4  \n",
       "9     3.6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=glass('https://www.glassdoor.co.in/Salaries/index.htm')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:1. Brand 2. Product Description 3. Price 4. Discount % using the url https://www.flipkart.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Writing Sunglasses in the search bar\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input').send_keys('Sunglasses')\n",
    "    \n",
    "    #Clicking on search button\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    brand=[]\n",
    "    pdis=[]\n",
    "    price=[]\n",
    "    dis=[]\n",
    "    \n",
    "    #Scraping from 3 pages\n",
    "    for i in range(3):\n",
    "    \n",
    "        #Scraping brand of the sunglasses\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "            brand.append(i.text)\n",
    "        \n",
    "        #Scraping description of the sunglasses\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[1]'):\n",
    "            if i.text is None:\n",
    "                pdis.append('No Data')\n",
    "            else:\n",
    "                pdis.append(i.text)\n",
    "       \n",
    "        #Scraping price\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "            if i.text is None:\n",
    "                price.append('No Data')\n",
    "            else:\n",
    "                price.append(i.text)\n",
    "     \n",
    "        #Scraping discount on the sunglasses    \n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "            if i.text is None:\n",
    "                dis.append('No Data')\n",
    "            else:\n",
    "                dis.append(i.text)\n",
    "        \n",
    "        #clicking on the next button\n",
    "        driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]').click()\n",
    "        time.sleep(4)\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['Brand']=brand[:100]\n",
    "    df['Decription']=pdis[:100]\n",
    "    df['Price']=price[:100]\n",
    "    df['Discount']=dis[:100]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Decription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (58)</td>\n",
       "      <td>₹525</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Villain</td>\n",
       "      <td>Others Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹539</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹225</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (61)</td>\n",
       "      <td>₹764</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Wayfarer, Round Sunglasses (63)</td>\n",
       "      <td>₹735</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Rectangular, Cat-eye Sunglasses ...</td>\n",
       "      <td>₹679</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Others Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,027</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                         Decription   Price  \\\n",
       "0           AISLIN      UV Protection, Gradient Round Sunglasses (58)    ₹525   \n",
       "1          Villain         Others Retro Square Sunglasses (Free Size)    ₹539   \n",
       "2           PIRASO              UV Protection Aviator Sunglasses (54)    ₹225   \n",
       "3           PIRASO              UV Protection Aviator Sunglasses (54)    ₹200   \n",
       "4           PIRASO              UV Protection Aviator Sunglasses (54)    ₹200   \n",
       "..             ...                                                ...     ...   \n",
       "95          AISLIN              UV Protection Cat-eye Sunglasses (61)    ₹764   \n",
       "96  ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹499   \n",
       "97          AISLIN      UV Protection Wayfarer, Round Sunglasses (63)    ₹735   \n",
       "98          AISLIN  UV Protection Rectangular, Cat-eye Sunglasses ...    ₹679   \n",
       "99          AISLIN      UV Protection, Others Aviator Sunglasses (58)  ₹1,027   \n",
       "\n",
       "   Discount  \n",
       "0   65% off  \n",
       "1   28% off  \n",
       "2   85% off  \n",
       "3   87% off  \n",
       "4   87% off  \n",
       "..      ...  \n",
       "95  76% off  \n",
       "96  75% off  \n",
       "97  77% off  \n",
       "98  72% off  \n",
       "99  72% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=flip('https://www.flipkart.com/')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone, i.e. 1. Rating 2. Review_summary 3. Full review. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Clicking on the review button to see all the reviews\n",
    "    driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    ra=[]\n",
    "    re=[]\n",
    "    res=[]\n",
    "    \n",
    "    #Scraping reviews until count dosent exceed 100\n",
    "    c=0\n",
    "    while c<100:\n",
    "        \n",
    "        #Scraping rating\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "            ra.append(i.text)\n",
    "            c+=1\n",
    "                \n",
    "        #Scrpaing short review\n",
    "        for i in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "            if i.text=='':\n",
    "                re.append('No Data')\n",
    "            else:\n",
    "                re.append(i.text)\n",
    "        \n",
    "        #SCraping Full Review\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]'):\n",
    "            if i.text=='':\n",
    "                res.append('No Data')\n",
    "            else:\n",
    "                res.append(i.text.replace('\\n',''))\n",
    "        \n",
    "        #Clicking on the Next Button\n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['Rating']=ra[:100]\n",
    "    df['Review Summary']=re[:100]\n",
    "    df['Full Review']=res[:100]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Really worth of money. i just love it. It is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Superb Product !!!A big and worthy upgrade fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5       Great product   \n",
       "3       5   Worth every penny   \n",
       "4       4         Good choice   \n",
       "..    ...                 ...   \n",
       "95      5            Terrific   \n",
       "96      5      Classy product   \n",
       "97      5  Highly recommended   \n",
       "98      5           Wonderful   \n",
       "99      5           Brilliant   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  Really worth of money. i just love it. It is t...  \n",
       "96  Superb Product !!!A big and worthy upgrade fro...  \n",
       "97  It's my first time to use iOS phone and I am l...  \n",
       "98  This is my first ever I phone. Before this I w...  \n",
       "99  I have migrated from OP 7pro... and trust me, ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=flip('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker : 1. Brand 2. Product Description 3. Price 4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Writing Sneakers on the search bar \n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input').send_keys('Sneakers')\n",
    "    #Clicking on the Search button\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    brand=[]\n",
    "    pdesc=[]\n",
    "    price=[]\n",
    "    dis=[]\n",
    "    \n",
    "    #Scraping reviews until count dosent exceed 100\n",
    "    c=0\n",
    "    while c<100:\n",
    "        \n",
    "        #Scraping brand of the sneaker\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "            brand.append(i.text)\n",
    "            c+=1\n",
    "        \n",
    "        #Scraping Description of the shoe\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/div'):\n",
    "            if i.text is None:\n",
    "                pdesc.append('No Data')\n",
    "            else:\n",
    "                pdesc.append(i.text)\n",
    "        \n",
    "        #Scraping price of the shoe\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "            if i.text is None:\n",
    "                price.append('No Data')\n",
    "            else:\n",
    "                price.append(i.text)\n",
    "                \n",
    "        #Scraping discount offered   \n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]/span'):\n",
    "            if i.text is None:\n",
    "                dis.append('No Data')\n",
    "            else:\n",
    "                dis.append(i.text)\n",
    "        \n",
    "        #Clicking on the next button\n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['Brand']=brand[:100]\n",
    "    df['Decription']=pdesc[:100]\n",
    "    df['Price']=price[:100]\n",
    "    df['Discount']=dis[:100]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Decription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oxpeo</td>\n",
       "      <td>oxpeo</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td></td>\n",
       "      <td>₹1,272</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India hub</td>\n",
       "      <td>DUCATI</td>\n",
       "      <td>₹404</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORICUM</td>\n",
       "      <td></td>\n",
       "      <td>₹377</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VIPSJAZZY</td>\n",
       "      <td>India hub</td>\n",
       "      <td>₹429</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Arohi</td>\n",
       "      <td>₹399</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td></td>\n",
       "      <td>₹419</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>Magnolia</td>\n",
       "      <td>₹283</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>JUBENTA</td>\n",
       "      <td></td>\n",
       "      <td>₹549</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand           Decription   Price Discount\n",
       "0       oxpeo                oxpeo    ₹398  60% off\n",
       "1      DUCATI                       ₹1,272  49% off\n",
       "2   India hub               DUCATI    ₹404  86% off\n",
       "3      ORICUM                         ₹377  62% off\n",
       "4   VIPSJAZZY            India hub    ₹429  57% off\n",
       "..        ...                  ...     ...      ...\n",
       "95     BRUTON                Arohi    ₹399  83% off\n",
       "96    Numenzo  World Wear Footwear    ₹398  60% off\n",
       "97  SCATCHITE                         ₹419  58% off\n",
       "98   HOTSTYLE             Magnolia    ₹283  43% off\n",
       "99    JUBENTA                         ₹549  45% off\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=flip('https://www.flipkart.com/')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black” And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myntra(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #Clicking on the price filter 6649 to 13099 \n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label').click()\n",
    "    time.sleep(1)\n",
    "    #Clicking on the color filter to black \n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label').click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    brand=[]\n",
    "    sdesc=[]\n",
    "    price=[]\n",
    "    \n",
    "    #Scraping reviews until count dosent exceed 100\n",
    "    c=0\n",
    "    while c<100:\n",
    "            #Scraping brand of the shoe\n",
    "            for i in driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]'):\n",
    "                brand.append(i.text)\n",
    "                c+=1\n",
    "                \n",
    "            #Scraping shoe description\n",
    "            for i in driver.find_elements_by_xpath('//h4[@class=\"product-product\"]'):\n",
    "                sdesc.append(i.text)\n",
    "                \n",
    "            #Scraping Price of the shoe\n",
    "            for i in driver.find_elements_by_xpath('//div[@class=\"product-price\"]'):\n",
    "                price.append(i.text)\n",
    "                \n",
    "            #Clicking on the next button\n",
    "            driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[11]/a').click()\n",
    "            time.sleep(1)\n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    df['Brand']=brand[:100]\n",
    "    df['Decription']=sdesc[:100]\n",
    "    df['Price']=price[:100]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Decription</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Woven Design Sneakers</td>\n",
       "      <td>Rs. 6749Rs. 14999(55% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Peep Toe Heels</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 7699Rs. 10999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD13 EP Basketball Shoes</td>\n",
       "      <td>Rs. 12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women PEGASUS 37 Running Shoes</td>\n",
       "      <td>Rs. 7496Rs. 9995(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Supra</td>\n",
       "      <td>Skytop Leather Casual Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR JORDAN Basketball</td>\n",
       "      <td>Rs. 8995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Onitsuka Tiger</td>\n",
       "      <td>Unisex TAI-CHI-REB Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Charged Bandit 6 Running</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM VOMERO Running</td>\n",
       "      <td>Rs. 10121Rs. 13495(25% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                      Decription  \\\n",
       "0              Cole Haan     Women Woven Design Sneakers   \n",
       "1   Heel & Buckle London            Women Peep Toe Heels   \n",
       "2              Cole Haan          Women Leather Sneakers   \n",
       "3                   Nike    Men KD13 EP Basketball Shoes   \n",
       "4                   Nike  Women PEGASUS 37 Running Shoes   \n",
       "..                   ...                             ...   \n",
       "95                 Supra     Skytop Leather Casual Shoes   \n",
       "96                  Nike       Men AIR JORDAN Basketball   \n",
       "97        Onitsuka Tiger     Unisex TAI-CHI-REB Sneakers   \n",
       "98          UNDER ARMOUR    Men Charged Bandit 6 Running   \n",
       "99                  Nike     Men AIR ZOOM VOMERO Running   \n",
       "\n",
       "                          Price  \n",
       "0    Rs. 6749Rs. 14999(55% OFF)  \n",
       "1     Rs. 7192Rs. 8990(20% OFF)  \n",
       "2    Rs. 7699Rs. 10999(30% OFF)  \n",
       "3                     Rs. 12995  \n",
       "4     Rs. 7496Rs. 9995(25% OFF)  \n",
       "..                          ...  \n",
       "95                     Rs. 7999  \n",
       "96                     Rs. 8995  \n",
       "97                     Rs. 8999  \n",
       "98    Rs. 7649Rs. 8999(15% OFF)  \n",
       "99  Rs. 10121Rs. 13495(25% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=myntra('https://www.myntra.com/shoes')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: 1. title 2. Ratings 3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon(url):\n",
    "    #Initializing Selenium Webdriver\n",
    "    driver=webdriver.Edge(r'C:\\Users\\aush1\\Downloads\\msedgedriver.exe')\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #Writing laptop in the search bar\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input').send_keys('Laptop')\n",
    "    #Clicking on the search button\n",
    "    driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input').click()\n",
    "    \n",
    "    #Clicking on the i7 filter\n",
    "    driver.find_element_by_xpath('//span[text()=\"Intel Core i7\"]').click()\n",
    "    #Clicking on the i9 filter\n",
    "    driver.find_element_by_xpath('//span[text()=\"Intel Core i9\"]').click()\n",
    "    \n",
    "    title=[]\n",
    "    ra=[]\n",
    "    price=[]\n",
    "    \n",
    "    #Scraping the laptop's title\n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"a-section a-spacing-none\"]/h2/a/span'):\n",
    "        title.append(i.text)\n",
    "        c=+1\n",
    "    \n",
    "    #Scrapimg Rating of the laptop\n",
    "    k=0\n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span'):\n",
    "        if k%2==0:\n",
    "            if i.get_attribute('aria-label')=='':\n",
    "                ra.append('No data')\n",
    "            else:\n",
    "                ra.append(i.get_attribute('aria-label'))\n",
    "        k+=1\n",
    "    \n",
    "    #Scraping the price of the laptop\n",
    "    for i in driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]'):\n",
    "        if i.text=='':\n",
    "            price.append('No Data')\n",
    "        else:\n",
    "            price.append(i.text)\n",
    "        \n",
    "    df=pd.DataFrame()\n",
    "    df['Title']=title[:10]\n",
    "    df['Ratings']=ra[:10]\n",
    "    df['Price']=price[:10]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vaio Z NZ14V3IN001P 14 inch/35.56 cm(Intel Cor...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>3,52,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>3.2 out of 5 stars</td>\n",
       "      <td>83,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>54,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "      <td>46,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>76,494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "      <td>1,74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>2.9 out of 5 stars</td>\n",
       "      <td>26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title             Ratings  \\\n",
       "0  Vaio Z NZ14V3IN001P 14 inch/35.56 cm(Intel Cor...  1.0 out of 5 stars   \n",
       "1  Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...  3.2 out of 5 stars   \n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.4 out of 5 stars   \n",
       "3  (Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...  3.0 out of 5 stars   \n",
       "4  Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...  5.0 out of 5 stars   \n",
       "5  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.5 out of 5 stars   \n",
       "6  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...  4.0 out of 5 stars   \n",
       "7  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  3.1 out of 5 stars   \n",
       "8  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  2.9 out of 5 stars   \n",
       "9  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...  4.7 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0  3,52,990  \n",
       "1    83,000  \n",
       "2    54,999  \n",
       "3    46,290  \n",
       "4    76,494  \n",
       "5    84,990  \n",
       "6    86,990  \n",
       "7  1,74,990  \n",
       "8    26,990  \n",
       "9    89,990  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=amazon('https://www.amazon.in/')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
